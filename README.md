# Meshed Worlds
A project I worked with 3 other people during HackMIT 2016!

This began as a way to combine the objects of the real world into a virtual environment. The idea was to interact with a virtually generated world by providing input from the physical environment. As a result, we used an approach which scans the real world environment and then generates a virtual reality world based on it. We used the Kinect for Windows to scan the environment and the Gear-VR for the 3D world generated. The main challenges we ran into were lack of documentation along with confusing instructions on how to approach this project. We started without any experience on any of these tools, so any minute step was a major accomplishment. We are very proud that we were able to scan and generate 3D environments. We learned that we should have spoken to Sponsors sooner about their technologies, and that Virtual 3D rendering is a huge skill set on it's own (that cannot be mastered in an overnight hack). The next step for this project would be to begin automating the entire set up, from scanning the environment all the way to rendering the world. (Note: for the demo files in this project, we scanned a few boxes which were in front of a wall. Furthermore, Unity was used to create the VR environment, and Blender was used to construct the objects from the meshes provided by the Kinect. Also, the actual meshes that we used as samples are left out as their sizes were too large in their raw format)).
